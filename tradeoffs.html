<!doctype html>
<head>
    <title>CS663 Research Tutorial</title>
    <link rel="stylesheet" href="index.css" />
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {},
            },
        };
    </script>
</head>
<body class="dark:bg-slate-800">
    <nav>
        <ul
            class="text-2xl flex flex-row justify-evenly slate-300 dark:slate-500 text-black dark:text-white"
        >
            <li>
                <a href="/"><div class="p-4">Abstract</div></a>
            </li>
            <li>
                <a href="/introduction"><div class="p-4">Introduction</div></a>
            </li>
            <li>
                <a href="/sensors"><div class="p-4">Sensors</div></a>
            </li>
            <li>
                <a href="/models"><div class="p-4">Models</div></a>
            </li>
            <li>
                <a href="/tradeoffs"><div class="p-4">Tradeoffs</div></a>
            </li>
            <li>
                <a href="/challenges">
                    <div class="p-4">Challenges</div>
                </a>
            </li>
            <li>
                <a href="/conclusions"><div class="p-4">Conclusions</div> </a>
            </li>
        </ul>
    </nav>
    <div class="p-8 w-full min-h-screen">
        <h1 class="mb-4 text-4xl text-center font-semibold dark:text-white">
            Effectiveness and Tradeoffs
        </h1>
        <p class="text-lg font-light w-1/2 mx-auto dark:text-white">
            &emsp; Given the computational challenge of providing depth
            estimation on a real-time feed from a sensor, choosing a performant
            sensor and model architecture is essential. For lower-end devices, a
            CNN is well-suited due to the simplicity of its operations. Vision
            Transformers and other complex approaches may not be suitable for
            such hardware. Additionally, a simple monocular camera would be the
            most widely-available option, as many mobile devices are equipped
            with one. For devices with better hardware or ones that rely on a
            network connection, more complex models could be viable though the
            constraints of working on an simple, accessible device would
            prohibit it.
        </p>
        <h1>Depth Maps</h1>
                            &emsp; The first tradeoff is that of quality over speed.
                    With respect to models, more complex architectures and
                    larger models can provide higher quality results at the cost
                    of requiring more computational power. As capable mobile
                    phones are, running a real-time depth estimation model is
                    computationally expensive. Unlike desktop devices which may
                    have a dedicated GPU that can parallelize convolutions and
                    attention computation, mobile phones are far more limited
                    and therefore model size is staunchly limited. Techniques
                    such as quantization can help reduce the size and increase
                    the speed of models at the cost of accuracy
                </p>
            </div>
            <div class="mt-2 p-4 w-1/2">
                <p class="my-auto">
                    &emsp; Performance can also be considered with respect to
                    the sensor. Depending on the quality of the camera being
                    used, a depth estimation model may be provided more
                    information as opposed to a lower quality camera. However,
                    such higher quality cameras may be more expensive for the
                    device.
                </p>
            </div>
            <div class="mt-2 p-4 w-1/2">
                <p class="my-auto">
                    &emsp; In addition to the performance itself, cost is of
                    paramount importance. If the cost constraints for the mob
                    device are relaxed, the device itself can have more
                    computational power, a better camera, and other features
                    that allow it to support larger or more complex models. The
                    acceptable cost would largely depend on the purpose of the
                    software utilizing the depth estimation model. For example,
                    for an accessibility app that notifies users of nearby
                    objects they may collide into, the cost constraints are
                    relatively strict as the software should be widely
                    accessible. There may be other scenarios such as creating a
                    depth map of a single scene where accessibility is not as
                    essential.
                </p>
            </div>

            <div
                class="mx-auto w-2/3 flex flex-row items-center justify-items-center font-light text-lg dark:text-white"
            >
            <div class="p-4 w-1/2">
                            <p class="my-auto">
            <div class="p-4 w-1/2">
                <figure>
                    <img
                        class="p-2 max-w-1/2 w-3/4 h-auto rounded-xl bg-slate-400"
                        src="https://i0.wp.com/education.civitai.com/wp-content/uploads/2023/10/depthmap-0000-1.png?resize=819%2C1024&ssl=1"
                        alt="Grayscale Depth Map of a Drink"
                    />
                </figure>
                <figcaption class="">
                    <a
                        class=""
                        href="https://education.civitai.com/civitai-guide-to-depth"
                        target="_blank"
                    >
                        <p
                            class="mx-auto p-1 text-blue-800 dark:text-blue-200 font-semibold text-center"
                        >
                            Depth Map Image of a Drink
                        </p>
                    </a>
                </figcaption>
            </div>
        </div>
    </div>
</body>
