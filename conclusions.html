<!DOCTYPE html>
<head>
    <title>CS663 Research Tutorial</title>
    <link rel="stylesheet" href="index.css" />
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {},
            },
        };
    </script>
</head>
<body class="dark:bg-slate-800">
    <nav>
        <ul
            class="text-2xl flex flex-row justify-evenly slate-300 dark:slate-500 text-black dark:text-white"
        >
            <li>
                <a href="/"><div class="p-4">Abstract</div></a>
            </li>
            <li>
                <a href="/introduction"><div class="p-4">Introduction</div></a>
            </li>
            <li>
                <a href="/sensors"><div class="p-4">Sensors</div></a>
            </li>
            <li>
                <a href="/models"><div class="p-4">Models</div></a>
            </li>
            <li>
                <a href="/tradeoffs"><div class="p-4">Tradeoffs</div></a>
            </li>
            <li>
                <a href="/challenges">
                    <div class="p-4">Challenges</div>
                </a>
            </li>
            <li>
                <a href="/conclusions"><div class="p-4">Conclusions</div> </a>
            </li>
        </ul>
    </nav>
    <div class="p-8 w-full min-h-screen">
        <h1 class="mb-4 text-4xl text-center font-semibold dark:text-white">
            Conclusions
        </h1>
        <p class="text-lg font-light w-1/2 mx-auto dark:text-white">
            &emsp; A system to provide depth information can be a useful asset
            to improve the capabilities of a visually-impaired person beyond
            traditional technologies. Furthermore, as models and hardware
            advance, the quality of depth information and efficiency of running
            inference will improve. Novel approaches continue to build on top of
            the original CNNs and Vision Transformers, incorporating new types
            of sensors as well. Furthermore, as application development and user
            experience research advances, there may be superior ways of
            developing such applications and conveying depth information.
        </p>
        <h2 class="p-2 text-3xl text-center dark:text-slate-200">
            Device Hardware
        </h2>
        <p class="text-lg font-light w-1/2 mx-auto dark:text-white">
            &emsp; As the hardware in mobile devices and servers improves and as
            more specialized hardware is developed, the capabilities of depth
            estimation models and applications will improve. While currently,
            smartphones do not have massive parallel processing as graphics
            chips do, future mobile devices might include more chips optimized
            for running machine learning models. Furthermore, general
            improvements in CPU, battery, networking, and memory would enable
            developers to pursue more complex methods that can produce better
            results. The manufacturing process for the hardware may also
            improve, resulting in reduced costs for all of the components.
        </p>
        <div class="mt-2 text-lg font-light w-1/3 mx-auto dark:text-white">
            <figure>
                <img
                    class="p-2 w-full h-auto rounded-xl bg-slate-400"
                    src="https://storage.googleapis.com/support-kms-prod/Gyz8RrsniyGo2AiA9XaHNStZru5YEXcGRfKP"
                    alt="Pixel 9 Pro Hardware Diagram"
                />
            </figure>
            <figcaption class="">
                <a
                    class=""
                    href="https://support.google.com/pixelphone/answer/7157629#zippy=%2Cpixel-pro"
                    target="_blank"
                >
                    <p
                        class="mx-auto p-1 text-blue-800 dark:text-blue-200 font-semibold text-center"
                    >
                        Google Pixel 9 Pro Hardware Diagram: 9, 11, and 12 are
                        Different Camera Lenses
                    </p>
                </a>
            </figcaption>
        </div>

        <h2 class="p-2 text-3xl text-center dark:text-slate-200">Sensors</h2>
        <p class="text-lg font-light w-1/2 mx-auto dark:text-white">
            &emsp; Though advanced sensors such as LiDAR are not as widely
            available as monocular cameras on smartphones, new sensors could be
            incorporated as mobile devices improve. It is possible that stereo
            vision may become more commonplace and models could incorporate the
            sensor into their input. Furthemore, as monocular cameras themselves
            acquire more color detail and capture higher-definition images,
            models may have more data to work with when inferring depth.
        </p>

        <div
            class="mt-5 text-center text-2xl font-light w-1/2 mx-auto dark:text-white"
        >
            If you haven&apos;t already, check out this
            <a
                class="text-blue-600 font-semibold"
                href="https://timm.haucke.xyz/monocular_depth_estimation_demo"
                target="_blank"
                >Open Source Depth Estimation Demo</a
            >!
        </div>
        <div class="mt-5 font-light w-1/2 mx-auto dark:text-white">
            <h2 class="p-2 text-3xl text-center dark:text-slate-200 font-semibold">Quiz</h2>
            <p class="my-2 text-xl font-light mx-auto dark:text-white">
                Which of the following Depth Estimation Models was designed
                specifically to be lightweight and provide fast inference on
                mobile devices?
            </p>
            <ol class="text-lg font-light mx-auto dark:text-white">
                <li>&dash; HiMODE</li>
                <li>&dash; METER</li>
                <li>&dash; CNN</li>
                <li>&dash; HybridDepth</li>
            <p class="my-2 text-xl font-light mx-auto dark:text-white">
                Which of the following sensors does HybridDepth use?
            </p>
            <ol class="text-lg font-light mx-auto dark:text-white">
                <li>&dash; Omnidirectional Camera</li>
                <li>&dash; Stereo Camera</li>
                <li>&dash; LiDAR</li>
                <li>&dash; Monocular Camera</li>
            </ol>
            <p class="my-2 text-xl font-light mx-auto dark:text-white">
                Which of the following is NOT included in the Spatial Residual Block in HiMODE?
            </p>
            <ol class="text-lg font-light mx-auto dark:text-white">
                <li>&dash; Convolution</li>
                <li>&dash; Linear Layer</li>
                <li>&dash; Max Pooling</li>
                <li>&dash; Zero Padding</li>
            </ol>
        </div>
    </div>
</body>
